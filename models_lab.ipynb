{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "facial-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "other-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn import Module, Linear\n",
    "from torch.nn import LeakyReLU, ReLU, Conv2d, ConvTranspose2d, Tanh\n",
    "from torch.nn import BatchNorm2d, Dropout, Dropout2d, Flatten\n",
    "\n",
    "from models.bayeslayers import BayesianLayer\n",
    "\n",
    "\n",
    "class BaseVariational(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x, debug=False):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            # if isinstance(layer, nn.Flatten):\n",
    "            #     print(x.shape)\n",
    "            if debug:\n",
    "                print(\"layer {}\".format(layer))\n",
    "                print(\"shape {}\".format(x.shape))\n",
    "                print(\"\")\n",
    "        return x\n",
    "\n",
    "    def predict(self, x, num_forward_passes=10):\n",
    "        pred = self.forward(x)\n",
    "        for i in range(num_forward_passes - 1):\n",
    "            pred += self.forward(x)\n",
    "        pred = pred / num_forward_passes\n",
    "\n",
    "        return latent\n",
    "\n",
    "    def kl_loss(self):\n",
    "        '''\n",
    "        Computes the KL divergence loss for all layers.\n",
    "        '''\n",
    "        kl = 0\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if isinstance(layer, BayesianLayer):\n",
    "                kl_ = layer.kl_divergence()\n",
    "                kl += kl_\n",
    "        return kl\n",
    "\n",
    "class CnnAE(torch.nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent_representation = self.encoder(x)\n",
    "        reconstruction = self.decoder(latent_representation)\n",
    "        return reconstruction\n",
    "\n",
    "    def predict(self, x, num_forward_passes=10):\n",
    "\n",
    "        latent_representation = self.encoder(x)\n",
    "        reconstruction = self.decoder(latent_representation)\n",
    "\n",
    "        for i in range(num_forward_passes - 1):\n",
    "            curr_latent = self.encoder(x)\n",
    "            latent_representation += curr_latent\n",
    "            reconstruction += self.decoder(curr_latent)\n",
    "        latent_representation = latent_representation / num_forward_passes\n",
    "        reconstruction = reconstruction / num_forward_passes\n",
    "\n",
    "        return latent_representation, reconstruction\n",
    "    def params(self):\n",
    "        return list(self.encoder.parameters()) + list(self.decoder.parameters())\n",
    "\n",
    "\n",
    "    def kl_loss(self):\n",
    "        '''\n",
    "        Computes the KL divergence loss for all layers.\n",
    "        '''\n",
    "        kl = 0\n",
    "        for i, layer in enumerate(self.encoder.layers):\n",
    "            if isinstance(layer, BayesianLayer):\n",
    "                kl_ = layer.kl_divergence()\n",
    "                kl += kl_\n",
    "        return kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "executive-craps",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "nervous-breeding",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-exclusion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "flexible-square",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md               sample2.zip             test_models.py\r\n",
      "\u001b[34mTrain\u001b[m\u001b[m                   small_ae_15_latents.txt zip_and_delete.py\r\n",
      "\u001b[34mmodels\u001b[m\u001b[m                  small_ae_25_latents.txt zipped_npy_2.zip\r\n",
      "models_lab.ipynb        sok_example.py\r\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "expensive-premium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  zipped_npy_2.zip\n",
      " extracting: states_gameplay_0.npy   \n",
      " extracting: states_scaled_gameplay_0.npy  \n",
      " extracting: actions_gameplay_0.npy  \n",
      " extracting: next_states_gameplay_0.npy  \n",
      " extracting: rewards_gameplay_0.npy  \n",
      " extracting: done_gameplay_0.npy     \n",
      " extracting: next_states_scaled_gameplay_0.npy  \n"
     ]
    }
   ],
   "source": [
    "! unzip zipped_npy_2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "premier-hurricane",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states_gameplay_0.npy\n",
      "states_scaled_gameplay_0.npy\n",
      "actions_gameplay_0.npy\n",
      "next_states_gameplay_0.npy\n",
      "rewards_gameplay_0.npy\n",
      "done_gameplay_0.npy\n",
      "next_states_scaled_gameplay_0.npy\n"
     ]
    }
   ],
   "source": [
    "files_here = listdir()\n",
    "np_files = [x for x in files_here if x.endswith('.npy')]\n",
    "actions = np.array([])\n",
    "next_states_scaled = np.array([])\n",
    "scaled = np.array([])\n",
    "\n",
    "for idx, file_name in enumerate(np_files):\n",
    "  with open(file_name, 'rb') as f:\n",
    "    current_array = np.load(f) \n",
    "  print(file_name)\n",
    "  if file_name.startswith('states_scaled'):\n",
    "    if len(scaled) == 0:\n",
    "      scaled = current_array\n",
    "    else:\n",
    "      scaled = np.concatenate([scaled, current_array])\n",
    "  elif file_name.startswith('next_states_scaled'):\n",
    "    if len(next_states_scaled) == 0:\n",
    "      next_states_scaled = current_array\n",
    "    else:\n",
    "      next_states_scaled = np.concatenate([next_states_scaled, current_array])\n",
    "  elif file_name.startswith('actions'):\n",
    "    if len(actions) == 0:\n",
    "      actions = current_array\n",
    "    else:\n",
    "      actions = np.concatenate([actions, current_array])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "tracked-market",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled, eval_scaled, train_next_states, eval_next_states = train_test_split(\n",
    "    scaled, next_states_scaled, test_size=0.15, random_state=42)\n",
    "\n",
    "train_actions, eval_actions = train_test_split(actions, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "transsexual-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, action_next_state=(None, None), transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.action, self.next_state = action_next_state       \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        items = x\n",
    "        if self.action is not None:\n",
    "            y = self.action[index]\n",
    "            z = self.next_state[index]\n",
    "            z = self.transform(z)\n",
    "            items = (x, y, z)\n",
    "\n",
    "        return items\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "means = torch.tensor([0.5, 0.5, 0.5], dtype=torch.float32)\n",
    "stds = torch.tensor([0.5, 0.5, 0.5], dtype=torch.float32)\n",
    "to_tensor = torchvision.transforms.Compose([\n",
    "                                torchvision.transforms.ToTensor(),\n",
    "                                torchvision.transforms.Normalize(\n",
    "                                                        mean=means,\n",
    "                                                        std=stds)\n",
    "                                             ])\n",
    "\n",
    "\n",
    "scaled_states_actions_dataset = MyDataset(train_scaled, (train_actions, train_next_states), transform=to_tensor)\n",
    "scaled_states_actions_loader = torch.utils.data.DataLoader(scaled_states_actions_dataset, batch_size=64,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "eval_scaled_states_actions_dataset = MyDataset(eval_scaled, (eval_actions , eval_next_states), transform=to_tensor)\n",
    "eval_scaled_states_actions_loader = torch.utils.data.DataLoader(eval_scaled_states_actions_dataset, batch_size=2,\n",
    "                                                    shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "medium-pitch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_img(img_tensor):\n",
    "    img = img_tensor[0]\n",
    "    denormed_img = denormalize(img)\n",
    "    plt.imshow(denormed_img.detach().numpy().transpose(1, 2, 0))\n",
    "    plt.show()\n",
    "\n",
    "def denormalize(normed_img):\n",
    "\n",
    "    return normed_img * stds[:, None, None] + means[:, None, None]\n",
    "\n",
    "_, (state, action, next_state) = next(enumerate(scaled_states_actions_loader))\n",
    "show_img(state)\n",
    "\n",
    "_, (state, action, next_state) = next(enumerate(eval_scaled_states_actions_loader))\n",
    "show_img(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "several-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepEncoderSmall(BaseVariational):\n",
    "    '''\n",
    "    Takes in as input batches of images of size [batch_size, 40, 40, 3]\n",
    "    '''\n",
    "    def __init__(self, latent_size=9):\n",
    "        super().__init__()\n",
    "        self.latent_size = latent_size\n",
    "        self.layers = torch.nn.ModuleList(self._init_layers())\n",
    "\n",
    "    def _init_layers(self):\n",
    "        layers = [\n",
    "                Conv2d(in_channels=3, out_channels=32,\n",
    "                      kernel_size=3, stride=2, padding=1),\n",
    "                ReLU(),\n",
    "                Conv2d(in_channels=32, out_channels=64,\n",
    "                          kernel_size=3, stride=2, padding=1),\n",
    "                ReLU(),\n",
    "                Conv2d(in_channels=64, out_channels=128,\n",
    "                          kernel_size=3, stride=2, padding=1),\n",
    "                BatchNorm2d(128),\n",
    "                ReLU(),\n",
    "                Conv2d(in_channels=128, out_channels=256,\n",
    "                          kernel_size=3, stride=2, padding=1),\n",
    "                ReLU(),\n",
    "                Conv2d(in_channels=256, out_channels=256,\n",
    "                          kernel_size=3, stride=3, padding=4),\n",
    "                ReLU(),\n",
    "                Conv2d(in_channels=256, out_channels=512,\n",
    "                          kernel_size=3, stride=1, padding=1),\n",
    "                BatchNorm2d(512),\n",
    "                ReLU(),\n",
    "                Conv2d(in_channels=512, out_channels=512,\n",
    "                          kernel_size=3, stride=3, padding=4),\n",
    "                BatchNorm2d(512),\n",
    "                ReLU(),\n",
    "                Conv2d(in_channels=512, out_channels=1024,\n",
    "                          kernel_size=3, stride=1, padding=1),\n",
    "                BatchNorm2d(1024),\n",
    "                ReLU(),\n",
    "                Conv2d(in_channels=1024, out_channels=1024,\n",
    "                          kernel_size=3, stride=3, padding=4),\n",
    "                BatchNorm2d(1024),\n",
    "                ReLU(),\n",
    "                Dropout2d(p=0.25),\n",
    "                Flatten(),\n",
    "                Dropout(p=0.4),\n",
    "                Linear(9216, int(9216 / 9)),\n",
    "                ReLU(),\n",
    "                Dropout(p=0.4),\n",
    "                BayesianLayer(int(9216 / 9), self.latent_size)]\n",
    "        return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "structured-florence",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "shape torch.Size([2, 32, 20, 20])\n",
      "\n",
      "layer ReLU()\n",
      "shape torch.Size([2, 32, 20, 20])\n",
      "\n",
      "layer Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "shape torch.Size([2, 64, 10, 10])\n",
      "\n",
      "layer ReLU()\n",
      "shape torch.Size([2, 64, 10, 10])\n",
      "\n",
      "layer Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "shape torch.Size([2, 128, 5, 5])\n",
      "\n",
      "layer BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "shape torch.Size([2, 128, 5, 5])\n",
      "\n",
      "layer ReLU()\n",
      "shape torch.Size([2, 128, 5, 5])\n",
      "\n",
      "layer Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "shape torch.Size([2, 256, 3, 3])\n",
      "\n",
      "layer ReLU()\n",
      "shape torch.Size([2, 256, 3, 3])\n",
      "\n",
      "layer Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "shape torch.Size([2, 512, 3, 3])\n",
      "\n",
      "layer BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "shape torch.Size([2, 512, 3, 3])\n",
      "\n",
      "layer ReLU()\n",
      "shape torch.Size([2, 512, 3, 3])\n",
      "\n",
      "layer Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "shape torch.Size([2, 1024, 3, 3])\n",
      "\n",
      "layer BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "shape torch.Size([2, 1024, 3, 3])\n",
      "\n",
      "layer ReLU()\n",
      "shape torch.Size([2, 1024, 3, 3])\n",
      "\n",
      "layer Conv2d(1024, 1024, kernel_size=(3, 3), stride=(3, 3), padding=(4, 4))\n",
      "shape torch.Size([2, 1024, 3, 3])\n",
      "\n",
      "layer BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "shape torch.Size([2, 1024, 3, 3])\n",
      "\n",
      "layer ReLU()\n",
      "shape torch.Size([2, 1024, 3, 3])\n",
      "\n",
      "layer Dropout2d(p=0.25, inplace=False)\n",
      "shape torch.Size([2, 1024, 3, 3])\n",
      "\n",
      "layer Flatten()\n",
      "shape torch.Size([2, 9216])\n",
      "\n",
      "layer Dropout(p=0.4, inplace=False)\n",
      "shape torch.Size([2, 9216])\n",
      "\n",
      "layer Linear(in_features=9216, out_features=1024, bias=True)\n",
      "shape torch.Size([2, 1024])\n",
      "\n",
      "layer ReLU()\n",
      "shape torch.Size([2, 1024])\n",
      "\n",
      "layer Dropout(p=0.4, inplace=False)\n",
      "shape torch.Size([2, 1024])\n",
      "\n",
      "layer BayesianLayer()\n",
      "shape torch.Size([2, 9])\n",
      "\n",
      "torch.Size([2, 3, 40, 40])\n"
     ]
    }
   ],
   "source": [
    "encoder = EncoderSmall(9)\n",
    "encoded = encoder(state, debug=True)\n",
    "print(state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "imported-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepDecoderSmall(BaseVariational):\n",
    "    '''\n",
    "    Use with SmallDecoder.\n",
    "    will take a Dense vector and turn it into batches of size [batch_size, 40, 40, 3]\n",
    "    '''\n",
    "    def __init__(self, latent_size):\n",
    "        super().__init__()\n",
    "        self.latent_size = latent_size\n",
    "        self.layers = torch.nn.ModuleList(self._init_layers())\n",
    "\n",
    "    def _init_layers(self):\n",
    "        self.start_decode = Linear(self.latent_size, int(9216 / 9))\n",
    "        self.drop_linear_one = Dropout(p=0.4)\n",
    "        self.start_decodeb = Linear(int(9216 / 9), 9216)\n",
    "        self.drop_linear_two = Dropout(p=0.4)\n",
    "        layers = [\n",
    "                ConvTranspose2d(in_channels=1024, out_channels=1024,\n",
    "                          kernel_size=3, stride=3, padding=3),\n",
    "                BatchNorm2d(1024),\n",
    "                Dropout2d(p=0.25),\n",
    "                ReLU(),\n",
    "                ConvTranspose2d(in_channels=1024, out_channels=1024,\n",
    "                          kernel_size=3, stride=3, padding=3),\n",
    "                BatchNorm2d(1024),\n",
    "                Dropout2d(p=0.25),\n",
    "                ReLU(),\n",
    "                ConvTranspose2d(in_channels=1024, out_channels=512,\n",
    "                          kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                BatchNorm2d(512),\n",
    "                Dropout2d(p=0.25),\n",
    "                ReLU(),\n",
    "                ConvTranspose2d(in_channels=512, out_channels=512,\n",
    "                          kernel_size=3, stride=3, padding=3),\n",
    "                BatchNorm2d(512),\n",
    "                Dropout2d(p=0.25),\n",
    "                ReLU(),\n",
    "                ConvTranspose2d(in_channels=512, out_channels=256,\n",
    "                          kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                BatchNorm2d(256),\n",
    "                ReLU(),\n",
    "                ConvTranspose2d(in_channels=256, out_channels=256,\n",
    "                          kernel_size=3, stride=3, padding=3),\n",
    "                BatchNorm2d(256),\n",
    "                ReLU(),\n",
    "                ConvTranspose2d(in_channels=256, out_channels=128,\n",
    "                          kernel_size=3, stride=2, padding=1),\n",
    "                BatchNorm2d(128),\n",
    "                ReLU(),\n",
    "                ConvTranspose2d(in_channels=128, out_channels=128,\n",
    "                          kernel_size=3, stride=3, padding=3),\n",
    "                BatchNorm2d(128),\n",
    "                ReLU(),\n",
    "                ConvTranspose2d(in_channels=128, out_channels=64,\n",
    "                      kernel_size=3, stride=2, padding=2),\n",
    "                BatchNorm2d(64),\n",
    "                ReLU(),\n",
    "                ConvTranspose2d(in_channels=64, out_channels=32,\n",
    "                          kernel_size=3, stride=1, padding=1),\n",
    "                BatchNorm2d(32),\n",
    "                ReLU(),\n",
    "                ConvTranspose2d(in_channels=32, out_channels=16,\n",
    "                                          kernel_size=3, stride=1, padding=1),\n",
    "                ReLU(),\n",
    "                BatchNorm2d(16),\n",
    "                Conv2d(in_channels=16, out_channels=8,\n",
    "                          kernel_size=4, stride=1, padding=1),\n",
    "                ReLU(),   \n",
    "                Conv2d(in_channels=8, out_channels=3,\n",
    "                          kernel_size=3, stride=1, padding=0),\n",
    "                Tanh()    \n",
    "            ]\n",
    "        return layers\n",
    "    \n",
    "    def forward(self, x, debug=False):\n",
    "        x = self.start_decode(x)\n",
    "        x = self.drop_linear_one(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.start_decodeb(x)\n",
    "        x = self.drop_linear_two(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.reshape(-1, 1024, 3, 3)\n",
    "\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "            if debug:\n",
    "                print(\"layer {}\".format(layer))\n",
    "                print(\"shape {}\".format(x.shape))\n",
    "                print(\"\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "thirty-charlotte",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer ConvTranspose2d(1024, 1024, kernel_size=(3, 3), stride=(3, 3), padding=(3, 3))\n",
      "shape torch.Size([2, 1024, 3, 3])\n",
      "\n",
      "layer BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "shape torch.Size([2, 1024, 3, 3])\n",
      "\n",
      "layer Dropout2d(p=0.25, inplace=False)\n",
      "shape torch.Size([2, 1024, 3, 3])\n",
      "\n",
      "layer ReLU()\n",
      "shape torch.Size([2, 1024, 3, 3])\n",
      "\n",
      "layer ConvTranspose2d(1024, 1024, kernel_size=(3, 3), stride=(3, 3), padding=(3, 3))\n",
      "shape torch.Size([2, 1024, 3, 3])\n",
      "\n",
      "layer BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "shape torch.Size([2, 1024, 3, 3])\n",
      "\n",
      "layer Dropout2d(p=0.25, inplace=False)\n",
      "shape torch.Size([2, 1024, 3, 3])\n",
      "\n",
      "layer ReLU()\n",
      "shape torch.Size([2, 1024, 3, 3])\n",
      "\n",
      "layer ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "shape torch.Size([2, 512, 6, 6])\n",
      "\n",
      "layer BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "shape torch.Size([2, 512, 6, 6])\n",
      "\n",
      "layer Dropout2d(p=0.25, inplace=False)\n",
      "shape torch.Size([2, 512, 6, 6])\n",
      "\n",
      "layer ReLU()\n",
      "shape torch.Size([2, 512, 6, 6])\n",
      "\n",
      "layer ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "shape torch.Size([2, 256, 12, 12])\n",
      "\n",
      "layer BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "shape torch.Size([2, 256, 12, 12])\n",
      "\n",
      "layer ReLU()\n",
      "shape torch.Size([2, 256, 12, 12])\n",
      "\n",
      "layer ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "shape torch.Size([2, 128, 23, 23])\n",
      "\n",
      "layer BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "shape torch.Size([2, 128, 23, 23])\n",
      "\n",
      "layer ReLU()\n",
      "shape torch.Size([2, 128, 23, 23])\n",
      "\n",
      "layer ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "shape torch.Size([2, 64, 43, 43])\n",
      "\n",
      "layer BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "shape torch.Size([2, 64, 43, 43])\n",
      "\n",
      "layer ReLU()\n",
      "shape torch.Size([2, 64, 43, 43])\n",
      "\n",
      "layer ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "shape torch.Size([2, 32, 43, 43])\n",
      "\n",
      "layer BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "shape torch.Size([2, 32, 43, 43])\n",
      "\n",
      "layer ReLU()\n",
      "shape torch.Size([2, 32, 43, 43])\n",
      "\n",
      "layer ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "shape torch.Size([2, 16, 43, 43])\n",
      "\n",
      "layer ReLU()\n",
      "shape torch.Size([2, 16, 43, 43])\n",
      "\n",
      "layer BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "shape torch.Size([2, 16, 43, 43])\n",
      "\n",
      "layer Conv2d(16, 8, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "shape torch.Size([2, 8, 42, 42])\n",
      "\n",
      "layer ReLU()\n",
      "shape torch.Size([2, 8, 42, 42])\n",
      "\n",
      "layer Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "shape torch.Size([2, 3, 40, 40])\n",
      "\n",
      "layer Tanh()\n",
      "shape torch.Size([2, 3, 40, 40])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoder = DecoderSmall(9)\n",
    "decoded = decoder(encoded, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "according-thumb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 40, 40])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ongoing-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallEncoder40(BaseVariational):\n",
    "    '''\n",
    "    Takes in as input batches of images of size [batch_size, 40, 40, 3]\n",
    "    '''\n",
    "    def __init__(self, latent_size, layers_dims, activation='relu'):\n",
    "        super().__init__()\n",
    "        self.latent_size = latent_size\n",
    "        self.layers_dims = layers_dims\n",
    "        self.activation = LeakyReLU if activation is not 'relu' else ReLU\n",
    "        self.layers = torch.nn.ModuleList(self._init_layers())\n",
    "\n",
    "    def _init_layers(self):\n",
    "        layers = []\n",
    "        for idx, dims in enumerate(self.layers_dims):\n",
    "            if idx == 0:\n",
    "                current_dims = 3\n",
    "                next_dims = dims\n",
    "            else:\n",
    "                current_dims = self.layers_dims[idx - 1]\n",
    "                next_dims = dims\n",
    "\n",
    "            layers.extend(\n",
    "                    [\n",
    "                    Conv2d(in_channels=current_dims, out_channels=next_dims,\n",
    "                           kernel_size=3, stride=2, padding=1),\n",
    "                    BatchNorm2d(next_dims),\n",
    "                    self.activation(),\n",
    "                    ])\n",
    "\n",
    "        flat_size = self.layers_dims[-1] * 5 * 5\n",
    "        layers.extend([\n",
    "                Flatten(),\n",
    "                Dropout(p=0.25),\n",
    "                Linear(flat_size, int(flat_size / 9)),\n",
    "                ReLU(),\n",
    "                #Dropout(p=0.4),\n",
    "                BayesianLayer(int(flat_size / 9), self.latent_size)]\n",
    "        )\n",
    "        return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ordinary-secretariat",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "shape torch.Size([2, 32, 20, 20])\n",
      "\n",
      "layer BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "shape torch.Size([2, 32, 20, 20])\n",
      "\n",
      "layer ReLU()\n",
      "shape torch.Size([2, 32, 20, 20])\n",
      "\n",
      "layer Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "shape torch.Size([2, 64, 10, 10])\n",
      "\n",
      "layer BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "shape torch.Size([2, 64, 10, 10])\n",
      "\n",
      "layer ReLU()\n",
      "shape torch.Size([2, 64, 10, 10])\n",
      "\n",
      "layer Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "shape torch.Size([2, 128, 5, 5])\n",
      "\n",
      "layer BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "shape torch.Size([2, 128, 5, 5])\n",
      "\n",
      "layer ReLU()\n",
      "shape torch.Size([2, 128, 5, 5])\n",
      "\n",
      "layer Flatten()\n",
      "shape torch.Size([2, 3200])\n",
      "\n",
      "layer Dropout(p=0.25, inplace=False)\n",
      "shape torch.Size([2, 3200])\n",
      "\n",
      "layer Linear(in_features=3200, out_features=355, bias=True)\n",
      "shape torch.Size([2, 355])\n",
      "\n",
      "layer ReLU()\n",
      "shape torch.Size([2, 355])\n",
      "\n",
      "layer BayesianLayer()\n",
      "shape torch.Size([2, 9])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [32, 64, 128]\n",
    "encoder = SmallEncoder40(9, layers_dims, 'relu')\n",
    "encoded = encoder(state, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "opening-graduation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallDecoder40(BaseVariational):\n",
    "    '''\n",
    "    Use with SmallEncoder40.\n",
    "    will take a Dense vector and turn it into batches of size [batch_size, 40, 40, 3]\n",
    "    '''\n",
    "    def __init__(self, latent_size, layers_dims, activation='relu'):\n",
    "        super().__init__()\n",
    "        self.latent_size = latent_size\n",
    "        self.layers_dims = layers_dims\n",
    "        self.activation = LeakyReLU if activation is not 'relu' else ReLU\n",
    "        self.layers = torch.nn.ModuleList(self._init_layers())\n",
    "\n",
    "    def _init_layers(self):\n",
    "        flat_size = self.layers_dims[0] * 5 * 5\n",
    "        self.start_decode = Linear(self.latent_size, int(flat_size / 9))\n",
    "        self.drop_linear_one = Dropout(p=0.4)\n",
    "        self.start_decodeb = Linear(int(flat_size / 9), flat_size)\n",
    "        self.drop_linear_two = Dropout(p=0.4)\n",
    "\n",
    "        stride = 3\n",
    "        padding = 3\n",
    "        output_padding = 0\n",
    "        layers = []\n",
    "        for idx, dims in enumerate(self.layers_dims):\n",
    "\n",
    "            if idx == 2:\n",
    "                current_dims = dims\n",
    "                next_dims = 8\n",
    "            else:\n",
    "                current_dims = dims\n",
    "                next_dims = self.layers_dims[idx + 1]\n",
    "\n",
    "            if idx == 2:\n",
    "                stride = 2\n",
    "                padding = 1\n",
    "                output_padding = 1\n",
    "\n",
    "            layers.extend(\n",
    "                [\n",
    "                Dropout2d(p=0.1),\n",
    "                ConvTranspose2d(in_channels=current_dims,\n",
    "                                 out_channels=next_dims,\n",
    "                                 kernel_size=3, stride=stride, padding=padding,\n",
    "                                 output_padding=output_padding),\n",
    "                BatchNorm2d(next_dims),\n",
    "                self.activation()\n",
    "                ]\n",
    "              )\n",
    "\n",
    "        layers.extend(\n",
    "                [Conv2d(in_channels=8, out_channels=3,\n",
    "                        kernel_size=3, stride=1, padding=0),\n",
    "                 Tanh()]\n",
    "                    )\n",
    "        return layers\n",
    "    \n",
    "    def forward(self, x, debug=False):\n",
    "        x = self.drop_linear_one(x)\n",
    "        x = self.start_decode(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.drop_linear_two(x)\n",
    "        x = self.start_decodeb(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        init_channels = self.layers_dims[0]\n",
    "        x = x.reshape(-1, init_channels, 5, 5)\n",
    "\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "            if debug:\n",
    "                print(\"layer {}\".format(layer))\n",
    "                print(\"shape {}\".format(x.shape))\n",
    "                print(\"\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "capable-momentum",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer Dropout2d(p=0.1, inplace=False)\n",
      "shape torch.Size([2, 128, 5, 5])\n",
      "\n",
      "layer ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(3, 3), padding=(3, 3))\n",
      "shape torch.Size([2, 64, 9, 9])\n",
      "\n",
      "layer BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "shape torch.Size([2, 64, 9, 9])\n",
      "\n",
      "layer LeakyReLU(negative_slope=0.01)\n",
      "shape torch.Size([2, 64, 9, 9])\n",
      "\n",
      "layer Dropout2d(p=0.1, inplace=False)\n",
      "shape torch.Size([2, 64, 9, 9])\n",
      "\n",
      "layer ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(3, 3), padding=(3, 3))\n",
      "shape torch.Size([2, 32, 21, 21])\n",
      "\n",
      "layer BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "shape torch.Size([2, 32, 21, 21])\n",
      "\n",
      "layer LeakyReLU(negative_slope=0.01)\n",
      "shape torch.Size([2, 32, 21, 21])\n",
      "\n",
      "layer Dropout2d(p=0.1, inplace=False)\n",
      "shape torch.Size([2, 32, 21, 21])\n",
      "\n",
      "layer ConvTranspose2d(32, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "shape torch.Size([2, 8, 42, 42])\n",
      "\n",
      "layer BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "shape torch.Size([2, 8, 42, 42])\n",
      "\n",
      "layer LeakyReLU(negative_slope=0.01)\n",
      "shape torch.Size([2, 8, 42, 42])\n",
      "\n",
      "layer Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "shape torch.Size([2, 3, 40, 40])\n",
      "\n",
      "layer Tanh()\n",
      "shape torch.Size([2, 3, 40, 40])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoder = SmallDecoder40(9, [128, 64, 32], 'leaky')\n",
    "decoded = decoder(encoded, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "chubby-monday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6524, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.nn.MSELoss()\n",
    "z = encoder(state)\n",
    "recon = decoder(z)\n",
    "loss(state, recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "brilliant-uganda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['states_gameplay_0.npy',\n",
       " 'states_scaled_gameplay_0.npy',\n",
       " 'actions_gameplay_0.npy',\n",
       " 'next_states_gameplay_0.npy',\n",
       " 'rewards_gameplay_0.npy',\n",
       " 'done_gameplay_0.npy',\n",
       " 'next_states_scaled_gameplay_0.npy']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for tiny\n",
    "files_here = listdir('zipped_npy')\n",
    "np_files = [x for x in files_here if x.endswith('.npy')]\n",
    "np_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "mighty-diagram",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states_gameplay_0.npy\n",
      "states_scaled_gameplay_0.npy\n",
      "actions_gameplay_0.npy\n",
      "next_states_gameplay_0.npy\n",
      "rewards_gameplay_0.npy\n",
      "done_gameplay_0.npy\n",
      "next_states_scaled_gameplay_0.npy\n"
     ]
    }
   ],
   "source": [
    "actions = np.array([])\n",
    "next_states_scaled = np.array([])\n",
    "scaled = np.array([])\n",
    "\n",
    "for idx, file_name in enumerate(np_files):\n",
    "    with open(\"zipped_npy/\"+file_name, 'rb') as f:\n",
    "        current_array = np.load(f) \n",
    "\n",
    "    print(file_name)\n",
    "    if file_name.startswith('states_scaled'):\n",
    "        if len(scaled) == 0:\n",
    "            scaled = current_array\n",
    "        else:\n",
    "            scaled = np.concatenate([scaled, current_array])\n",
    "    elif file_name.startswith('next_states_scaled'):\n",
    "        if len(next_states_scaled) == 0:\n",
    "            next_states_scaled = current_array\n",
    "        else:\n",
    "            next_states_scaled = np.concatenate([next_states_scaled, current_array])\n",
    "    elif file_name.startswith('actions'):\n",
    "        if len(actions) == 0:\n",
    "            actions = current_array\n",
    "        else:\n",
    "            actions = np.concatenate([actions, current_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "important-butterfly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8c939a49b0>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(scaled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "empty-bundle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zipped_npy_tiny/next_states_scaled_gameplay_0.npy'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"zipped_npy_tiny/\"+file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "everyday-battle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states_gameplay_0.npy\n"
     ]
    }
   ],
   "source": [
    "actions = np.array([])\n",
    "next_states_scaled = np.array([])\n",
    "scaled = np.array([])\n",
    "\n",
    "file_name = 'states_gameplay_0.npy'\n",
    "with open(file_name, 'rb') as f:\n",
    "    current_array = np.load(f) \n",
    "\n",
    "print(file_name)\n",
    "if file_name.startswith('states_scaled'):\n",
    "    if len(scaled) == 0:\n",
    "        scaled = current_array\n",
    "    else:\n",
    "        scaled = np.concatenate([scaled, current_array])\n",
    "elif file_name.startswith('next_states_scaled'):\n",
    "    if len(next_states_scaled) == 0:\n",
    "        next_states_scaled = current_array\n",
    "    else:\n",
    "        next_states_scaled = np.concatenate([next_states_scaled, current_array])\n",
    "elif file_name.startswith('actions'):\n",
    "    if len(actions) == 0:\n",
    "        actions = current_array\n",
    "    else:\n",
    "        actions = np.concatenate([actions, current_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "other-inspiration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 160, 160, 3)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "hired-citizen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8c6ad55ba8>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(current_array[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-export",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = encoded(state)\n",
    "model_mu = torch.nn.Linear( , latent_dim)\n",
    "model_logvar = torch.nn.Linear( , latent_dim)\n",
    "\n",
    "mu = model_mu(x)\n",
    "logvar = model_logvar(x)\n",
    "\n",
    "z = reparameterize(mu, logvar)\n",
    "\n",
    "def reparameterize(self, mu, log_var):\n",
    "    \"\"\"\n",
    "    :param mu: mean from the encoder's latent space\n",
    "    :param log_var: log variance from the encoder's latent space\n",
    "    \"\"\"\n",
    "    std = torch.exp(0.5*log_var) # standard deviation\n",
    "    eps = torch.randn_like(std) # `randn_like` as we need the same size\n",
    "    sample = mu + (eps * std) # sampling as if coming from the input space\n",
    "    return sample\n",
    "\n",
    "\n",
    "KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "thesis_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
